{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The packages to be installed before running the code\n",
    "! pip3 install -qU guardrails-ai openai langchain_community langchain_experimental langchain-upstage sentence-transformers langchainhub langchain-chroma langchain matplotlib python-dotenv tavily-python ragas faiss-cpu tokenizers \n",
    "!pip install -qU python-dotenv\n",
    "!pip install -qU PyPDF2\n",
    "!pip install -qU langchain\n",
    "!pip install -qU langchain-community\n",
    "!pip install -qU langchain-core\n",
    "!pip install -qU langchain-text-splitters\n",
    "!pip install -qU langchain_upstage\n",
    "!pip install -qU oracledb\n",
    "print(\"======== Job Completed ========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "(os.environ[\"UPSTAGE_API_KEY\"],os.environ[\"DB_USER\"],os.environ[\"DB_PASSWORD\"]),\n",
    "(os.environ[\"DSN\"]),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import array\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import oracledb\n",
    "from langchain_community.vectorstores import oraclevs\n",
    "from langchain_community.vectorstores.oraclevs import OracleVS\n",
    "\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_core.documents import BaseDocumentTransformer, Document\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Successfully imported libraries and modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username=os.environ[\"DB_USER\"]\n",
    "password=os.environ[\"DB_PASSWORD\"]\n",
    "dsn=os.environ[\"DSN\"]\n",
    "\n",
    "con = oracledb.connect(user=username, password=password, dsn=dsn)\n",
    "\n",
    "try: \n",
    "    conn23c = oracledb.connect(user=username, password=password, dsn=dsn)\n",
    "    print(\"Connection successful!\", conn23c.version)\n",
    "except Exception as e:\n",
    "    print(\"Connection failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import UpstageEmbeddings\n",
    "upstage_embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "\n",
    "vector_store = OracleVS(client=conn23c, \n",
    "                        embedding_function=upstage_embeddings, \n",
    "                        table_name=\"pre_diagnostic_db\", \n",
    "                        distance_strategy=DistanceStrategy.DOT_PRODUCT)\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "import os\n",
    "from tavily import TavilyClient\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage()\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "\n",
    "def intelligence_rag(question):\n",
    "  total_result = []\n",
    "\n",
    "  # 1. LLM 결과 \n",
    "  rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "      [\n",
    "          (\"system\", \"You are a helpful assistant.\"),\n",
    "          (\"human\", \"{input}\"),\n",
    "      ]\n",
    "  )\n",
    "  chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "  chain_result = chain.invoke({\"input\": question})\n",
    "  total_result.append(chain_result)\n",
    "\n",
    "  # 2. 뉴스 결과\n",
    "  x = tavily.search(query=question)\n",
    "  # Extracting the content of the first two results\n",
    "  first_two_contents = [result['content'] for result in x['results'][:2]]\n",
    "  total_result.append(first_two_contents)\n",
    "\n",
    "  # 3. RAG\n",
    "  result_chunks=vector_store.similarity_search(question, k = 2)\n",
    "  total_result.append(result_chunks)\n",
    "  \n",
    "  return total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 들어가는 문장 확인\n",
    "context = intelligence_rag('너는 일차진료기관의 아프리카의 의사야. 어제부터 38도 이상의 발열이 지속된 26세 여성 환자가 내원하였어. 필요한 검사와 진단, 치료를 말해주고 그 이유를 step-by-step 으로 알려줘. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 결과 출력\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Please provide answer for question from the following context. \n",
    "    ---\n",
    "    Question: {question}\n",
    "    ---\n",
    "    Context: {context}\n",
    "    \"\"\"\n",
    ")\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "chain.invoke({\"context\": context, \"question\": '너는 일차진료기관의 아프리카의 의사야. 어제부터 38도 이상의 발열이 지속된 26세 여성 환자가 내원하였어. 필요한 검사와 진단, 치료를 말해주고 그 이유를 step-by-step 으로 알려줘. '})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 결과 출력\n",
    "user_question = (\"A 30-year-old male with no unusual medical history presents with a fever and a positive malaria RCT test. Which drug would you prescribe? Answer with reasons.  \")\n",
    "country = \"Korea\"\n",
    "print (\"The prompt to the LLM will be:\",user_question)\n",
    "\n",
    "if user_question:\n",
    "    s3time =  time.time()\n",
    "    # Look up the chunks that are most similar to the user's question in this case AI vector search\n",
    "    # k is a top-k parameter\n",
    "    result_chunks=vector_store.similarity_search(user_question, k = 2)\n",
    "    s4time = time.time()\n",
    "    print(f\"Search for the user question in the Oracle Database 23ai and return similar chunks duration: {round(s4time - s3time, 1)} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Please provide most correct answer from the following context. \n",
    "\n",
    "    Think step by step and look the html tags and table values carefully to provide the most correct answer.\n",
    "\n",
    "    ---\n",
    "    role : You are a doctor in a primary care organization in a {country}.\n",
    "    ---\n",
    "    Question: {question}\n",
    "    ---\n",
    "    Context: {context}\n",
    "    ---\n",
    "    Tell me the necessary tests, diagnoses, treatments, and prescriptions (pharmaceuticals) and tell me why.\n",
    "\n",
    "    Let's think step by step.\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt_template | llm | StrOutputParser()\n",
    "chain.invoke({\"context\": result_chunks, \"question\": user_question, \"country\":country})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 평가 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "s1 = \"\"\"According to the WHO guidelines for malaria treatment, artemisinin-based combination therapy (ACT) is recommended as the first-line treatment for Plasmodium falciparum in Pakistan. \n",
    "Currently, the most commonly used ACT in Pakistan is artesunate-amodiaquine (AS-AQ). \n",
    "However, in this patient's case, treatment for Plasmodium vivax must also be considered. Plasmodium vivax is one of the prevalent malaria species in the region. \n",
    "For Plasmodium vivax, chloroquine (CQ) is recommended as the first-line treatment.\n",
    "However, considering the possibility of CQ-resistant Plasmodium vivax, it is essential to review recent treatment efficacy studies conducted in Pakistan to verify if CQ remains highly effective in the region.\n",
    "If CQ is found to be highly effective, it should be prescribed for 3 days (25mg/kg on the first day, followed by 12.5mg/kg for the next 2 days), and the treatment efficacy should be monitored.\n",
    "If the efficacy of CQ is low or resistance has developed, alternative treatments such as artesunate-mefloquine (AS-MQ) or tafenoquine should be considered.\n",
    "The efficacy of the prescribed treatment should be monitored, and appropriate follow-up actions should be taken in case of treatment failure or adverse effects.\n",
    "Therefore, it is advisable to verify the current efficacy of CQ in the region, considering the possibility of CQ-resistant Plasmodium vivax. If CQ is effective, it should be prescribed for 3 days and the treatment efficacy monitored. If CQ efficacy is low or resistance has developed, alternative treatments should be considered.\"\"\"\n",
    "\n",
    "s2 = \"Although I am not a doctor, according to the given context, if a 30-year-old male with no significant medical history tests positive for malaria by RDT, it is recommended to prescribe Artemisinin-based combination therapy (ACT). In Pakistan, combinations such as Artesunate-Amodiaquine (AS-AQ) or Artesunate-Mefloquine (AS-MQ) are commonly used. The physician will prescribe either AS-AQ or AS-MQ and provide guidance on the appropriate dosage and schedule. Additionally, the physician will monitor for any potential side effects during treatment and follow up with the patient for a certain period to confirm the treatment's effectiveness and monitor for any recurrence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "\n",
    "def calculate_bertscore(sentence1, sentence2, lang=\"en\"):\n",
    "    \"\"\"\n",
    "    Calculate BERTScore for two sentences.\n",
    "    \n",
    "    Args:\n",
    "    sentence1 (str): First sentence.\n",
    "    sentence2 (str): Second sentence.\n",
    "    lang (str): Language of the sentences (default: 'en' for English).\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary containing precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    # BERTScore requires lists of sentences\n",
    "    sentences1 = [sentence1]\n",
    "    sentences2 = [sentence2]\n",
    "\n",
    "    # Calculate BERTScore\n",
    "    P, R, F1 = score(sentences1, sentences2, lang=lang)\n",
    "    \n",
    "    # Convert scores to scalar values\n",
    "    result = {\n",
    "        \"Precision\": P.item(),\n",
    "        \"Recall\": R.item(),\n",
    "        \"F1 Score\": F1.item()\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example sentences\n",
    "# sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "# sentence2 = \"A fast, dark-colored fox leaps over a sleepy dog.\n",
    "\n",
    "# Calculate and print BERTScore\n",
    "result = calculate_bertscore(s1, s2, lang=\"en\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
